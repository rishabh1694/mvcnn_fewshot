{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import configs\n",
    "from data.datamgr_ssl import SetDataManager\n",
    "import backbone\n",
    "from methods.protonet_ssl import ProtoNet\n",
    "# from model_resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = dict(\n",
    "            Conv4 = backbone.Conv4,\n",
    "            Conv4S = backbone.Conv4S,\n",
    "            Conv6 = backbone.Conv6,\n",
    "            ResNet10 = backbone.ResNet10,\n",
    "            ResNet18 = backbone.ResNet18,\n",
    "            ResNet34 = backbone.ResNet34,\n",
    "            ResNet50 = backbone.ResNet50,\n",
    "            ResNet101 = backbone.ResNet101,\n",
    "            resnet18 = 'resnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = 'train'\n",
    "parser = argparse.ArgumentParser(description= 'few-shot script %s' %(script))\n",
    "parser.add_argument('--dataset'     , default='CUB',        help='CUB/miniImagenet/cross/omniglot/cross_char')\n",
    "parser.add_argument('--model'       , default='Conv4',      help='model: Conv{4|6} / ResNet{10|18|34|50|101}') # 50 and 101 are not used in the paper\n",
    "parser.add_argument('--method'      , default='baseline',   help='baseline/baseline++/protonet/matchingnet/relationnet{_softmax}/maml{_approx}') #relationnet_softmax replace L2 norm with softmax to expedite training, maml_approx use first-order approximation in the gradient for efficiency\n",
    "parser.add_argument('--train_n_way' , default=5, type=int,  help='class num to classify for training') #baseline and baseline++ would ignore this parameter\n",
    "parser.add_argument('--test_n_way'  , default=5, type=int,  help='class num to classify for testing (validation) ') #baseline and baseline++ only use this parameter in finetuning\n",
    "parser.add_argument('--n_shot'      , default=5, type=int,  help='number of labeled data in each class, same as n_support') #baseline and baseline++ only use this parameter in finetuning\n",
    "parser.add_argument('--n_query'      , default=16, type=int,  help='number of query images')\n",
    "parser.add_argument('--num_views'   , default=0, type=int,  help='number of rendered views for each model')\n",
    "parser.add_argument('--train_aug'   , action='store_true',  help='perform data augmentation or not during training ') #still required for save_features.py and test.py to find the model path correctly\n",
    "parser.add_argument('--jigsaw'      , action='store_true',  help='multi-task training')\n",
    "parser.add_argument('--lbda'        , default=0.0, type=float,  help='lambda for the jigsaw loss, (1-lambda) for proto loss')\n",
    "parser.add_argument('--rotation'    , action='store_true',  help='multi-task training')\n",
    "parser.add_argument('--no_bn'        , action='store_true',  help='not using batch norm if True')\n",
    "\n",
    "if script == 'train':\n",
    "    parser.add_argument('--num_classes' , default=200, type=int, help='total number of classes in softmax, only used in baseline') #make it larger than the maximum label value in base class\n",
    "    parser.add_argument('--save_freq'   , default=50, type=int, help='Save frequency')\n",
    "    parser.add_argument('--start_epoch' , default=0, type=int,help ='Starting epoch')\n",
    "    parser.add_argument('--stop_epoch'  , default=-1, type=int, help ='Stopping epoch') #for meta-learning methods, each epoch contains 100 episodes. The default epoch number is dataset dependent. See train.py\n",
    "    parser.add_argument('--lr'  , default=0.001, type=float, help ='Learning Rate')\n",
    "    parser.add_argument('--resume'      , action='store_true', help='continue from previous trained model with largest epoch')\n",
    "    parser.add_argument('--warmup'      , action='store_true', help='continue from baseline, neglected if resume is true') #never used in the paper\n",
    "\n",
    "params = parser.parse_args('--dataset ModelNet --model resnet18 --method protonet --n_shot 1 --jigsaw --lbda 0.5 --no_bn'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     params = parser.parse_args()\n",
    "\n",
    "# np.random.seed(10) #Why do we need to set this random seed?\n",
    "\n",
    "base_file = configs.data_dir[params.dataset] + 'base.json' \n",
    "val_file   = configs.data_dir[params.dataset] + 'val.json'\n",
    "\n",
    "#what about test file?\n",
    "\n",
    "if 'Conv' in params.model:\n",
    "    image_size = 84\n",
    "else:\n",
    "    image_size = 224 #for modelnet decide based on model architecture\n",
    "\n",
    "optimization = 'Adam'\n",
    "# start_epoch = 0\n",
    "start_epoch = params.start_epoch\n",
    "stop_epoch = 400\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '4,5'\n",
    "# CUDA_VISIBLE_DEVICES=6,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabhgupta/miniconda3/envs/py37/lib/python3.7/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "#code from mvcnn, add logging later\n",
    "#parse_args\n",
    "\n",
    "# num_models = 1000 #max number of models to use per class, add this functionality later\n",
    "# n_models_train = num_models*num_views\n",
    "\n",
    "# if params.num_views and params.num_views >=5:\n",
    "#     n_query = max(1, int(8* params.test_n_way/params.train_n_way)) #why is this required?\n",
    "# else:\n",
    "#     n_query = max(1, int(16* params.test_n_way/params.train_n_way)) #why is this required?\n",
    "\n",
    "ssl_params = dict(jigsaw = params.jigsaw, lbda=params.lbda, rotation = params.rotation)\n",
    "train_few_shot_params    = dict(n_way = params.train_n_way, n_support = params.n_shot) \n",
    "\n",
    "base_datamgr            = SetDataManager(image_size, n_query = params.n_query,  **train_few_shot_params, num_views = params.num_views, **ssl_params)\n",
    "base_loader             = base_datamgr.get_data_loader(base_file , aug = params.train_aug)\n",
    "\n",
    "test_few_shot_params     = dict(n_way = params.test_n_way, n_support = params.n_shot)\n",
    "val_datamgr             = SetDataManager(image_size, n_query = params.n_query, **test_few_shot_params, num_views = params.num_views, **ssl_params)\n",
    "val_loader              = val_datamgr.get_data_loader(val_file, aug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking: False\n",
      "tracking in block: False\n",
      "tracking in block: False\n",
      "tracking: False\n",
      "tracking in block: False\n",
      "tracking in block: False\n",
      "tracking: False\n",
      "tracking in block: False\n",
      "tracking in block: False\n",
      "tracking: False\n",
      "tracking in block: False\n",
      "tracking in block: False\n"
     ]
    }
   ],
   "source": [
    "backbone = model_dict[params.model]\n",
    "model = ProtoNet(backbone, params.num_views, **train_few_shot_params, **ssl_params, use_bn=(not params.no_bn))\n",
    "model = model.cuda()\n",
    "# model = torch.nn.DataParallel(model).cuda()\n",
    "# model.feature = model.feature.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.checkpoint_dir = '%s/checkpoints/%s/%s_%s' %(configs.save_dir, params.dataset, params.model, params.method)\n",
    "if params.train_aug:\n",
    "    params.checkpoint_dir += '_aug'\n",
    "params.checkpoint_dir += '_%dway_%dshot_%dviews_lr%f' %(params.train_n_way, params.n_shot, params.num_views, params.lr)\n",
    "## Add jigsaw\n",
    "if params.jigsaw:\n",
    "    params.checkpoint_dir += '_jigsawonly_alldata_lbda%.2f'%(params.lbda)\n",
    "## Add rotation\n",
    "if params.rotation:\n",
    "    params.checkpoint_dir += '_rotation_lbda%.2f'%(params.lbda)\n",
    "\n",
    "if not os.path.isdir(params.checkpoint_dir):\n",
    "    os.makedirs(params.checkpoint_dir)\n",
    "    \n",
    "if params.resume:\n",
    "    resume_file = get_resume_file(params.checkpoint_dir)\n",
    "    if resume_file is not None:\n",
    "        tmp = torch.load(resume_file)\n",
    "        start_epoch = tmp['epoch']+1\n",
    "        model.load_state_dict(tmp['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(base_loader, val_loader, model, optimization, start_epoch, stop_epoch, params):    \n",
    "    if optimization == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=params.lr)\n",
    "    else:\n",
    "       raise ValueError('Unknown optimization, please define by yourself')\n",
    "\n",
    "    max_acc = 0       \n",
    "\n",
    "    for epoch in range(start_epoch,stop_epoch):\n",
    "        model.train()\n",
    "        model.train_loop(epoch, base_loader,  optimizer ) #model are called by reference, no need to return \n",
    "        model.eval()\n",
    "\n",
    "        if not os.path.isdir(params.checkpoint_dir):\n",
    "            os.makedirs(params.checkpoint_dir)\n",
    "\n",
    "        if params.jigsaw:\n",
    "            acc, acc_jigsaw = model.test_loop( val_loader)\n",
    "        elif params.rotation:\n",
    "            acc, acc_rotation = model.test_loop( val_loader)\n",
    "        else:    \n",
    "            acc = model.test_loop( val_loader)\n",
    "        \n",
    "        if acc > max_acc : #for baseline and baseline++, we don't use validation in default and we let acc = -1, but we allow options to validate with DB index\n",
    "            print(\"best model! save...\")\n",
    "            max_acc = acc\n",
    "            outfile = os.path.join(params.checkpoint_dir, 'best_model.tar')\n",
    "            torch.save({'epoch':epoch, 'state':model.state_dict()}, outfile)\n",
    "\n",
    "        if (epoch % params.save_freq==0) or (epoch==stop_epoch-1):\n",
    "            outfile = os.path.join(params.checkpoint_dir, '{:d}.tar'.format(epoch))\n",
    "            torch.save({'epoch':epoch, 'state':model.state_dict()}, outfile)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Batch 10/100 | Loss 10.161418 | Loss Proto 16.923388 | Loss Jigsaw 3.399449\n",
      "Epoch 0 | Batch 20/100 | Loss 6.432936 | Loss Proto 9.416476 | Loss Jigsaw 3.449395\n",
      "Epoch 0 | Batch 30/100 | Loss 5.126857 | Loss Proto 6.790006 | Loss Jigsaw 3.463709\n",
      "Epoch 0 | Batch 40/100 | Loss 4.481714 | Loss Proto 5.491719 | Loss Jigsaw 3.471711\n",
      "Epoch 0 | Batch 50/100 | Loss 4.096579 | Loss Proto 4.705557 | Loss Jigsaw 3.487602\n",
      "Epoch 0 | Batch 60/100 | Loss 3.835398 | Loss Proto 4.176051 | Loss Jigsaw 3.494745\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-46bd34d9385e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-549275823ed1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(base_loader, val_loader, model, optimization, start_epoch, stop_epoch, params)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_loader\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0moptimizer\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m#model are called by reference, no need to return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mvcnn_fewshot/methods/protonet_ssl.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, epoch, train_loader, optimizer)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjigsaw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train(base_loader, val_loader,  model, optimization, start_epoch, stop_epoch, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
